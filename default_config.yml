### train
device: -2 # -1 for using cpu, 0 for single gpu, -2 for dynamically picking single gpu, [0,1,2,3] for multiple gpus
num_epochs: 25
batch_size: 8192
learning_rate: 0.0001
load_pretrained_model: False
model_type: MLR
use_language_model_encoder: False
language_model_encoder_name: roberta-base
encoder_hidden_dim: 768
# weight
downvote_weight: 1
user_normalization: equal # null for no normalization, equal for assigning user weight = 1/votes,
# data processing
save_and_load_prepared_data: True
sample_ratio: 1
sample_method: ['most_votes', "equal_up_down_votes"]
sparse_features_embed_dims: {'SUBMISSION_ID': 256, 'USERNAME': 256, 'SUBREDDIT': 32, 'AUTHOR': 32}
dense_features: ['CREATED_TIME', 'NSFW']
use_voted_users_feature: True
sample_part_voted_users: True
add_target_user_ratio: 0.35
prepared_data_path: data/reddit/prepared_data.pt
train_at_least_n_votes: 0
train_test_different_submissions: False
submission_text_dict_path: data/reddit/submission_text_dict.pt


### curation modeling
upvote_downvote_ratio_thres: 0.9
user_grouping_method: "neural" # or "votes", "single_user_as_group", "manual"
manual_user_groups: null
active_user_votes_thres: 5
group_user_num_lower_thres: 5
group_user_num_upper_thres: 500
preferred_submissions_venn_figure_dir: output/figures/preferred_subs