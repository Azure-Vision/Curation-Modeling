### train
device: -2 # -1 for using cpu, 0 for single gpu, -2 for dynamically picking single gpu, [0,1,2,3] for multiple gpus
num_epochs: 25
batch_size: 8192
learning_rate: 0.0001
load_pretrained_model: False
model_type: MLR
use_language_model_encoder: False
language_model_encoder_name: roberta-base
encoder_hidden_dim: 768
l2_normalization: 0.00001
loss_function: binary_crossentropy
eval_metrics: ["acc"] # ['binary_crossentropy', "auc", "acc"]
# weight
downvote_weight: 3
user_normalization: equal_total # null for no normalization, equal_total for assigning user weight = 1/votes, equal_upvote_downvote for equal upvote weight and downvote weight for each user!
minority_vote_normalization: False
# data processing
save_and_load_prepared_data: True
sample_ratio: 1
sample_method: ['most_votes'] # , "equal_up_down_votes", "add_weak_downvote"
categorical_features: ['USERNAME', 'AUTHOR'] # 'SUBMISSION_ID' #! make sure "USERNAME" is the first one
string_features: ['SUBREDDIT', "CREATED_TIME", 'NSFW', "SUBMISSION_TEXT"]
use_voted_users_feature: True # will add "UPVOTED_USERS" and "DOWNVOTED_USERS"
sample_part_voted_users: True
add_target_user_ratio: 0.35
prepared_data_path: data/reddit/prepared_data.pt
train_at_least_n_votes: 0 # for each posts, train with "train_at_least_n_votes" votes, and test on other votes
train_test_different_submissions: False
submission_text_dict_path: data/reddit/submission_text_dict.pt


### curation modeling
upvote_downvote_ratio_thres: 0.5
user_grouping_method: "votes" # or "neural", "all_user_as_group", "single_user_as_group", "manual", "predict_all_submissions", "none", "votes all_user_as_group". "vote" for using voting matrix and PCA for clustering; "none" for no curation

manual_user_groups: null
active_user_votes_thres: 3
group_user_num_lower_thres: 1
group_user_num_upper_thres: 40
preferred_submissions_venn_figure_dir: output/figures/preferred_subs