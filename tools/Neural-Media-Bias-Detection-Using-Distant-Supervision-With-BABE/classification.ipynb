{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this script, you need the following files found in the /data directory:\n",
    "- \"final_labels_SG1.xlsx\"\n",
    "- \"final_labels_SG2.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4kqNVQx-pD4"
   },
   "source": [
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10170,
     "status": "ok",
     "timestamp": 1620807725268,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "92Q3zPSjalf0",
    "outputId": "7e49e098-6a0a-4610-a2db-ac228510ac44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1460,
     "status": "ok",
     "timestamp": 1620807730492,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9d2EFrDIUXUG",
    "outputId": "3892b8b3-d418-4bc1-beaa-2d2d869a2b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/TableSense/largedisk/wanrong/Curation-Modeling/tools/Neural-Media-Bias-Detection-Using-Distant-Supervision-With-BABE\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26553,
     "status": "ok",
     "timestamp": 1620807760914,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "667g0q9jYX8D",
    "outputId": "7a26b416-bb27-4bd0-b375-d54d5f8b5018"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, List, Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertConfig, TFBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from transformers import ElectraTokenizer, TFElectraForSequenceClassification\n",
    "from transformers import XLNetTokenizer, TFXLNetForSequenceClassification\n",
    "from transformers import LongformerTokenizer, TFLongformerForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1620807761508,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "abdzY7ARYX8M"
   },
   "outputs": [],
   "source": [
    "# set seed, TF uses python ramdom and numpy library, so these must also be fixed\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1620807763097,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "DkbVcSRQppUw",
    "outputId": "c12cff5d-911f-4a71-cf14-0068ca0ee54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if hardware accelerator available\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6078,
     "status": "ok",
     "timestamp": 1620807767043,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "Pboq8uWHq2oe",
    "outputId": "c4c0bdcf-f0ea-41f6-cc75-428543d96641"
   },
   "outputs": [],
   "source": [
    "# tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlNn9cexsKPx"
   },
   "source": [
    "If GPUs are available, tensorflow will give priority to it automatically and computations will be performed on the GPU as default. That behavior can be changed by assigning a task explicitly to a device. Example:\n",
    "\n",
    "```\n",
    "with tf.device('/CPU:0'):\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-sm3aAxZr5R"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1620809519238,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "k3AlX8qqroZE",
    "outputId": "64de8fc8-ec64-4e7b-8caf-78bbd1c85a5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>Label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Orange Is the New Black\" star Yael Stone is r...</td>\n",
       "      <td>https://www.foxnews.com/entertainment/australi...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>environment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We have one beautiful law,\" Trump recently sa...</td>\n",
       "      <td>https://www.alternet.org/2020/06/law-and-order...</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>gun control</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['bizarre', 'characteristically']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...immigrants as criminals and eugenics, all o...</td>\n",
       "      <td>https://www.nbcnews.com/news/latino/after-step...</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['criminals', 'fringe', 'extreme']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...we sounded the alarm in the early months of...</td>\n",
       "      <td>https://www.alternet.org/2019/07/fox-news-has-...</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>‘A new low’: Washington Post media critic blow...</td>\n",
       "      <td>https://www.alternet.org/2019/08/a-new-low-was...</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['blows', 'up', 'absurd', 'lies', 'nationalism...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  \"Orange Is the New Black\" star Yael Stone is r...   \n",
       "1  \"We have one beautiful law,\" Trump recently sa...   \n",
       "2  ...immigrants as criminals and eugenics, all o...   \n",
       "3  ...we sounded the alarm in the early months of...   \n",
       "9  ‘A new low’: Washington Post media critic blow...   \n",
       "\n",
       "                                           news_link    outlet  \\\n",
       "0  https://www.foxnews.com/entertainment/australi...  Fox News   \n",
       "1  https://www.alternet.org/2020/06/law-and-order...  Alternet   \n",
       "2  https://www.nbcnews.com/news/latino/after-step...     MSNBC   \n",
       "3  https://www.alternet.org/2019/07/fox-news-has-...  Alternet   \n",
       "9  https://www.alternet.org/2019/08/a-new-low-was...  Alternet   \n",
       "\n",
       "               topic  type  Label_bias                          label_opinion  \\\n",
       "0        environment   2.0           0                       Entirely factual   \n",
       "1        gun control   0.0           1  Somewhat factual but also opinionated   \n",
       "2  white-nationalism   0.0           1             Expresses writer’s opinion   \n",
       "3  white-nationalism   0.0           1  Somewhat factual but also opinionated   \n",
       "9  white-nationalism   0.0           1             Expresses writer’s opinion   \n",
       "\n",
       "                                        biased_words  \n",
       "0                                                 []  \n",
       "1                  ['bizarre', 'characteristically']  \n",
       "2                 ['criminals', 'fringe', 'extreme']  \n",
       "3                                                 []  \n",
       "9  ['blows', 'up', 'absurd', 'lies', 'nationalism...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_sg1 = \"data/final_labels_SG1.xlsx\"\n",
    "PATH_sg2 = \"data/final_labels_SG2.xlsx\"\n",
    "df_sg1 = pd.read_excel(PATH_sg1, engine='openpyxl')\n",
    "df_sg2 = pd.read_excel(PATH_sg2, engine='openpyxl')\n",
    "df_sg1.rename(columns={'text': 'sentence', 'label_bias': 'Label_bias'}, inplace=True)\n",
    "df_sg2.rename(columns={'text': 'sentence', 'label_bias': 'Label_bias'}, inplace=True)\n",
    "\n",
    "# binarize classification problem\n",
    "df_sg1 = df_sg1[df_sg1['Label_bias']!='No agreement']\n",
    "df_sg1 = df_sg1[df_sg1['Label_bias'].isna()==False]\n",
    "df_sg1.replace(to_replace='Biased', value=1, inplace=True)\n",
    "df_sg1.replace(to_replace='Non-biased', value=0, inplace=True)\n",
    "df_sg1[\"type\"] = df_sg1[\"type\"].map({\"left\": 0, \"center\": 1, \"right\": 2})\n",
    "\n",
    "df_sg2 = df_sg2[df_sg2['Label_bias']!='No agreement']\n",
    "df_sg2 = df_sg2[df_sg2['Label_bias'].isna()==False]\n",
    "df_sg2.replace(to_replace='Biased', value=1, inplace=True)\n",
    "df_sg2.replace(to_replace='Non-biased', value=0, inplace=True)\n",
    "df_sg2[\"type\"] = df_sg2[\"type\"].map({\"left\": 0, \"center\": 1, \"right\": 2})\n",
    "df_sg2 = df_sg2[df_sg2['type'].isna()==False]\n",
    "df_sg2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1620808980811,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "pRzJDtTif2iH"
   },
   "outputs": [],
   "source": [
    "# Stratified k-Fold instance\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzQYIT1wCG-m"
   },
   "source": [
    "The rest of the preprocessing needs to be performed inside the folds as a) encoder layers shouldn't be allowed to see whole data to construct the lookups and b) indexing with skfold is not possible when data is in tensorflow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions called in skfold loop\n",
    "\n",
    "def pd_to_tf(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset\"\"\"\n",
    "    target = df.pop('type')\n",
    "    # target = df.pop('Label_bias')\n",
    "    sentence = df.pop('sentence')\n",
    "    return tf.data.Dataset.from_tensor_slices((sentence.values, target.values))\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "  plt.show()\n",
    "\n",
    "def tokenize(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset and run hugging face's tokenizer on data\"\"\"\n",
    "    target = df.pop('type')\n",
    "    # target = df.pop('Label_bias')\n",
    "    sentence = df.pop('sentence')\n",
    "\n",
    "    train_encodings = tokenizer(\n",
    "                        sentence.tolist(),                      \n",
    "                        add_special_tokens = True, # add [CLS], [SEP]\n",
    "                        truncation = True, # cut off at max length of the text that can go to BERT\n",
    "                        padding = True, # add [PAD] tokens\n",
    "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_encodings), \n",
    "         target.tolist()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUMxPAGdYX8W"
   },
   "source": [
    "## Attention-based models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "81dd8afd3da148c084f84b3d34329812",
      "fc5f1f66fc694d668251a47e1e379f8b",
      "1ff2fa37c94e412c836224c447fe6bf7",
      "bfaab7f593fb4bd088a64592a8b53663",
      "d632b1a86e4e4492b99cf549e3f021ec",
      "c9f8a2524f8a4c17a197a8078e31ce49",
      "46ce1f04fe3140f5962fa05c7cc71f28",
      "5c3ba5b9183d4fe697e84337907920b8",
      "6c52cabb9ece48b58ceb073437fdc439",
      "e46833e1a05e48ae8b1c6087bb00ee0f",
      "23855aa0fb6244d98d5044da23814836",
      "dbeee3b64dc94284a4775f2a0cb4dfa4",
      "c2f751936f5746ae939295cb88367292",
      "d3245d896e7c4f158ab0b4da76ea93a4",
      "3b6867a6625c4f9890040cabfc57f3a7",
      "caceb8515d614c109d4f74848530aa51",
      "79df1255843b48aabe25b5ff547b5783",
      "d19186b71be744899b772642934539e1",
      "bafa4dd539714c5b8100494b9b5bf071",
      "553ed5546d45464db8cfa1c67fee040a",
      "ca24677e1d2f4431a14c60ba268bf0fb",
      "81e01b1fc1824ae6a795c324f05d43f7",
      "d499b2c8dc88467ca3fb077c364163cf",
      "311c872733504f0a804f73f6f49a9ea4"
     ]
    },
    "executionInfo": {
     "elapsed": 3002,
     "status": "ok",
     "timestamp": 1620809353803,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "QIIWDGdwTZap",
    "outputId": "6d87f2cf-43a0-4c6b-d872-cc60bb07ac60"
   },
   "outputs": [],
   "source": [
    "def run_model_5fold(df_train, model_name, freeze_encoder=True, pretrained=False, plot=False):\n",
    "  \"\"\"\"freeze flags whether encoder layer should be frozen to not destroy transfer learning. Only set to false when enough data is provided\"\"\"\n",
    "\n",
    "  # these variables will be needed for skfold to select indices\n",
    "  Y = df_train['type']\n",
    "  # Y = df_train['Label_bias']\n",
    "  X = df_train['sentence']\n",
    "\n",
    "  # hyperparams\n",
    "  BUFFER_SIZE = 10000\n",
    "  BATCH_SIZE = 32\n",
    "  k = 1\n",
    "\n",
    "  val_loss = []\n",
    "  val_acc = []\n",
    "  val_prec = []\n",
    "  val_rec = []\n",
    "  val_f1 = []\n",
    "  val_f1_micro = []\n",
    "  val_f1_wmacro = []\n",
    "\n",
    "  for train_index, val_index in skfold.split(X,Y):\n",
    "    print('### Start fold {}'.format(k))\n",
    "    \n",
    "    # split into train and validation set\n",
    "    train_dataset = df_train.iloc[train_index]\n",
    "    val_dataset = df_train.iloc[val_index]\n",
    "\n",
    "    # prepare data for transformer\n",
    "    train_dataset = tokenize(train_dataset)\n",
    "    val_dataset = tokenize(val_dataset)\n",
    "\n",
    "    # mini-batch it\n",
    "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # create new model\n",
    "    if model_name == 'bert':\n",
    "      model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "    if model_name == 'distilbert':\n",
    "      model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n",
    "    elif model_name == 'roberta':\n",
    "      model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "    elif model_name == 'electra':\n",
    "      model = TFElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator', num_labels=3)\n",
    "    elif model_name == 'xlnet':\n",
    "      model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=3)\n",
    "    # save model\n",
    "    model.save_pretrained('./models/{}'.format(model_name))\n",
    "    \n",
    "\n",
    "    if freeze_encoder == True:\n",
    "      for w in model.get_layer(index=0).weights:\n",
    "        w._trainable = False\n",
    "\n",
    "    # compile it\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) \n",
    "    model.compile(optimizer=optimizer, loss=model.compute_loss) \n",
    "\n",
    "    # transfer learning\n",
    "    if pretrained == True:\n",
    "      model.get_layer(index=0).set_weights(trained_model_layer) # load bias-specific weights\n",
    "      #model.load_weights('./checkpoints/')\n",
    "    \n",
    "    # after 2 epochs without improvement, stop training\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "    # fit it\n",
    "    history = model.fit(train_dataset, epochs=10, validation_data = val_dataset, callbacks=[callback])\n",
    "    \n",
    "    # plot history\n",
    "    if plot:\n",
    "      plot_graphs(history,'loss')\n",
    "\n",
    "    # evaluate\n",
    "    loss = model.evaluate(val_dataset)\n",
    "    \n",
    "    if model_name == 'xlnet':\n",
    "      yhats = []\n",
    "      for row in df_train.iloc[val_index]['sentence']:\n",
    "        input = tokenizer(row, return_tensors=\"tf\")\n",
    "        output = model(input)\n",
    "        logits = output.logits.numpy()[0]\n",
    "        candidates = logits.tolist()\n",
    "        decision = candidates.index(max(candidates))\n",
    "        yhats.append(decision)\n",
    "    else:\n",
    "      logits = model.predict(val_dataset)  \n",
    "      yhats = []\n",
    "      for i in logits[0]:\n",
    "        # assign class label according to highest logit\n",
    "        candidates = i.tolist()\n",
    "        decision = candidates.index(max(candidates))\n",
    "        yhats.append(decision)\n",
    "    \n",
    "    y = []\n",
    "    for text, label in val_dataset.unbatch():   \n",
    "      y.append(label.numpy())\n",
    "    \n",
    "    val_loss.append(loss)\n",
    "    val_acc.append(accuracy_score(y, yhats))\n",
    "    print(\"Acc\", accuracy_score(y, yhats))\n",
    "    val_prec.append(precision_score(y, yhats, average='macro'))\n",
    "    val_rec.append(recall_score(y, yhats, average='macro'))\n",
    "    val_f1.append(f1_score(y, yhats, average='macro'))\n",
    "    val_f1_micro.append(f1_score(y, yhats, average='micro'))\n",
    "    val_f1_wmacro.append(f1_score(y, yhats, average='weighted'))\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model.save_pretrained('./models/{}'.format(model_name))\n",
    "    k += 1\n",
    "\n",
    "  return val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCWs4EWjy4Kp"
   },
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643764,
     "status": "ok",
     "timestamp": 1620810209794,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "AV-PUSinUJnF",
    "outputId": "04cccd2e-997d-402e-83dc-537d3fcde5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 165s 4s/step - loss: 1.0493 - val_loss: 1.0375\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 144s 4s/step - loss: 1.0074 - val_loss: 0.9707\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 145s 4s/step - loss: 0.7792 - val_loss: 0.9311\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 141s 4s/step - loss: 0.3370 - val_loss: 1.1210\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.9311\n",
      "Acc 0.5838709677419355\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 197s 5s/step - loss: 1.0293 - val_loss: 0.9531\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 176s 5s/step - loss: 0.8389 - val_loss: 0.9903\n",
      "10/10 [==============================] - 10s 966ms/step - loss: 0.9531\n",
      "Acc 0.4919093851132686\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 203s 5s/step - loss: 1.0622 - val_loss: 1.0246\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 175s 5s/step - loss: 0.9467 - val_loss: 0.9257\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 171s 4s/step - loss: 0.6698 - val_loss: 0.9973\n",
      "10/10 [==============================] - 9s 911ms/step - loss: 0.9257\n",
      "Acc 0.5242718446601942\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 196s 5s/step - loss: 1.0304 - val_loss: 0.9940\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 176s 5s/step - loss: 0.8551 - val_loss: 1.0575\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9940\n",
      "Acc 0.42394822006472493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 196s 5s/step - loss: 1.0276 - val_loss: 0.9930\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 175s 4s/step - loss: 0.8936 - val_loss: 0.9320\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 169s 4s/step - loss: 0.5695 - val_loss: 0.9824\n",
      "10/10 [==============================] - 10s 948ms/step - loss: 0.9320\n",
      "Acc 0.5048543689320388\n",
      "5-Fold CV Loss: 0.9471697688102723\n",
      "5-Fold CV Accuracy: 0.5057709573024324\n",
      "5-Fold CV Precision: 0.48639225003100617\n",
      "5-Fold CV Recall: 0.48554703903309704\n",
      "5-Fold CV F1 Score: 0.4651019179824238\n",
      "5-Fold CV Micro F1 Score: 0.5057709573024324\n",
      "5-Fold CV Weighted Macro F1 Score: 0.4818895164133871\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# without distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='bert', freeze_encoder=False, pretrained=False)\n",
    "\n",
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4OJmwP2ziMa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 327s 5s/step - loss: 0.9914 - val_loss: 0.9097\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 308s 5s/step - loss: 0.7859 - val_loss: 0.8582\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 308s 5s/step - loss: 0.4622 - val_loss: 0.8865\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8582\n",
      "Acc 0.611214953271028\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TableSense/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/67 [=>............................] - ETA: 4:27 - loss: 1.1435"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# without distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='bert', freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062081,
     "status": "ok",
     "timestamp": 1620811281215,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "KI34Fj7zzAIh",
    "outputId": "71c4ed35-69a9-40d0-ca5e-97e028858ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT on SG2\n",
      "5-Fold CV Loss: 0.8832831859588623\n",
      "5-Fold CV Accuracy: 0.5899499457453884\n",
      "5-Fold CV Precision: 0.5962224353722474\n",
      "5-Fold CV Recall: 0.6007675671746269\n",
      "5-Fold CV F1 Score: 0.5830446261476042\n",
      "5-Fold CV Micro F1 Score: 0.5899499457453884\n",
      "5-Fold CV Weighted Macro F1 Score: 0.5763379436017781\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9t6QsLC5Oou"
   },
   "source": [
    "### BERT + distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6042,
     "status": "ok",
     "timestamp": 1620811602006,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "tufL8EEl5NvY",
    "outputId": "0735c4a6-55e3-47ae-d28f-082baa1680f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model layer weights from pretraining on distant dataset \n",
    "# compile model\n",
    "#transfer_model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "transfer_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "transfer_model.compile(optimizer=optimizer, loss=transfer_model.compute_loss) \n",
    "\n",
    "transfer_model.load_weights('./checkpoints/bert_final_checkpoint_news_headlines_USA')\n",
    "trained_model_layer = transfer_model.get_layer(index=0).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp6TOmLP42nZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# with distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1620812125259,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "JGq54KK_5u1I",
    "outputId": "57b86c26-6288-4496-b3fd-8e5a93dde077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT + distant on SG1\n",
      "5-Fold CV Loss: 0.4784796714782715\n",
      "5-Fold CV Accuracy: 0.7791283150506451\n",
      "5-Fold CV Precision: 0.782222153066104\n",
      "5-Fold CV Recall: 0.7624161073825504\n",
      "5-Fold CV F1 Score: 0.7690257043162897\n",
      "5-Fold CV Micro F1 Score: 0.7791283150506451\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7782424758051683\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT + distant on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss4XWht750Ff"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# with distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 994709,
     "status": "ok",
     "timestamp": 1620813141542,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "QmIN7OV155p3",
    "outputId": "d75bfae9-9499-4581-9b8a-445abf7d9d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT + distant on SG2\n",
      "5-Fold CV Loss: 0.45280778408050537\n",
      "5-Fold CV Accuracy: 0.8047893380785556\n",
      "5-Fold CV Precision: 0.8010278449136129\n",
      "5-Fold CV Recall: 0.8082872928176796\n",
      "5-Fold CV F1 Score: 0.8027645188619399\n",
      "5-Fold CV Micro F1 Score: 0.8047893380785558\n",
      "5-Fold CV Weighted Macro F1 Score: 0.8043577261879854\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT + distant on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCW0oaxBzonB"
   },
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqw59Djszq2X"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='distilbert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1620811585894,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "-j4gNOr9z9Tk",
    "outputId": "d7d77ed0-0180-4be2-a09f-2c6370a0ac51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DistilBERT on SG1\n",
      "5-Fold CV Loss: 0.5034848332405091\n",
      "5-Fold CV Accuracy: 0.7603517841381919\n",
      "5-Fold CV Precision: 0.7851353351520555\n",
      "5-Fold CV Recall: 0.7006711409395974\n",
      "5-Fold CV F1 Score: 0.736955546776338\n",
      "5-Fold CV Micro F1 Score: 0.7603517841381919\n",
      "5-Fold CV Weighted Macro F1 Score: 0.758224422060177\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for DistilBERT on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHqfzE-jz4lm"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='distilbert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515463,
     "status": "ok",
     "timestamp": 1620813683857,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9kt0gOdy0ALD",
    "outputId": "44839d74-8c34-4050-f15f-463c805d47f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DistilBERT on SG2\n",
      "5-Fold CV Loss: 0.47459145188331603\n",
      "5-Fold CV Accuracy: 0.7783788392741292\n",
      "5-Fold CV Precision: 0.7914496007137517\n",
      "5-Fold CV Recall: 0.756353591160221\n",
      "5-Fold CV F1 Score: 0.768966991077014\n",
      "5-Fold CV Micro F1 Score: 0.7783788392741293\n",
      "5-Fold CV Weighted Macro F1 Score: 0.777102422253571\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for DistilBERT on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTchi-m2hYh"
   },
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSUsyFiz2kTV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.training.experimental.mixed_precision' has no attribute 'register_loss_scale_wrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f3726c0e3f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='roberta', \n\u001b[0;32m----> 3\u001b[0;31m                                                                                             freeze_encoder=False, pretrained=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-7ffd5fb9ae1c>\u001b[0m in \u001b[0;36mrun_model_5fold\u001b[0;34m(df_train, model_name, freeze_encoder, pretrained, plot)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'roberta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'electra'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFElectraForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google/electra-small-discriminator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/keras/utils/version_utils.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLayerVersionSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m   \u001b[0;34m\"\"\"Chooses between Keras v1 and v2 Layer class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cr4/lib/python3.6/site-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m mixed_precision.register_loss_scale_wrapper(optimizer_v2.OptimizerV2,\n\u001b[0m\u001b[1;32m   1205\u001b[0m                                             LossScaleOptimizerV1)\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute 'register_loss_scale_wrapper'"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1620814269788,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "bmGQKU3h22jD",
    "outputId": "0bfd3c9d-54cc-40d4-a96c-d7efe1d297d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa on SG1\n",
      "5-Fold CV Loss: 0.4697426736354828\n",
      "5-Fold CV Accuracy: 0.7784621527339974\n",
      "5-Fold CV Precision: 0.7825771209819836\n",
      "5-Fold CV Recall: 0.7758389261744967\n",
      "5-Fold CV F1 Score: 0.7715627724463581\n",
      "5-Fold CV Micro F1 Score: 0.7784621527339974\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7752193988259601\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajU2IyFX2563"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1620816413940,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "oJCJpFDy3AY5",
    "outputId": "70c6f7bd-59cb-474e-eee0-2c8f8f9a0560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa on SG2\n",
      "5-Fold CV Loss: 0.45095362067222594\n",
      "5-Fold CV Accuracy: 0.8007054811025227\n",
      "5-Fold CV Precision: 0.7834945430249991\n",
      "5-Fold CV Recall: 0.8337016574585636\n",
      "5-Fold CV F1 Score: 0.8042913565026074\n",
      "5-Fold CV Micro F1 Score: 0.8007054811025227\n",
      "5-Fold CV Weighted Macro F1 Score: 0.799347878132545\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOMwgdo9H2Ax"
   },
   "source": [
    "### RoBERTa + distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33368,
     "status": "ok",
     "timestamp": 1620816448547,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "xgmGx_olHxw0",
    "outputId": "5c714802-dcdf-4e50-e685-b6c57215a78e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model layer weights from pretraining on distant dataset \n",
    "# compile model\n",
    "transfer_model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "transfer_model.compile(optimizer=optimizer, loss=transfer_model.compute_loss) \n",
    "\n",
    "transfer_model.load_weights('./checkpoints/roberta_final_checkpoint_news_headlines_USA')\n",
    "trained_model_layer = transfer_model.get_layer(index=0).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pevLAcJCH_qD"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634561,
     "status": "ok",
     "timestamp": 1620817049768,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "Vs_brFmCIDPk",
    "outputId": "6dab2001-bc9d-424e-db19-ce41d95fe2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa + distant on SG1\n",
      "5-Fold CV Loss: 0.44771517515182496\n",
      "5-Fold CV Accuracy: 0.7985668053629219\n",
      "5-Fold CV Precision: 0.7758359785184737\n",
      "5-Fold CV Recall: 0.832214765100671\n",
      "5-Fold CV F1 Score: 0.7999256262460596\n",
      "5-Fold CV Micro F1 Score: 0.7985668053629217\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7977665899984501\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa + distant on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105085,
     "status": "ok",
     "timestamp": 1620818309017,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "IQ_FG4ysIAVi",
    "outputId": "0ad63d17-e8b9-4dc4-997c-15bcb245017c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5349WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 97s 877ms/step - loss: 0.5345 - val_loss: 0.4133\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 78s 845ms/step - loss: 0.3409 - val_loss: 0.4796\n",
      "23/23 [==============================] - 5s 234ms/step - loss: 0.4133\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5679WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 95s 874ms/step - loss: 0.5673 - val_loss: 0.4084\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.3456 - val_loss: 0.4032\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.2353 - val_loss: 0.5046\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.4032\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5390WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 96s 875ms/step - loss: 0.5386 - val_loss: 0.4585\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.3569 - val_loss: 0.4767\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.4585\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5427WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 97s 882ms/step - loss: 0.5422 - val_loss: 0.4699\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 78s 845ms/step - loss: 0.3178 - val_loss: 0.4695\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 78s 844ms/step - loss: 0.2017 - val_loss: 0.5180\n",
      "23/23 [==============================] - 5s 233ms/step - loss: 0.4695\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5487WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 89s 800ms/step - loss: 0.5482 - val_loss: 0.4198\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 70s 765ms/step - loss: 0.3592 - val_loss: 0.4554\n",
      "23/23 [==============================] - 6s 263ms/step - loss: 0.4198\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1103746,
     "status": "ok",
     "timestamp": 1620818309018,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "hqneQf2yIFmR",
    "outputId": "45fa5790-08c0-404c-9a6f-18a8bd85a602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa + distant on SG2\n",
      "5-Fold CV Loss: 0.4328740358352661\n",
      "5-Fold CV Accuracy: 0.8007017738975699\n",
      "5-Fold CV Precision: 0.8479610779798031\n",
      "5-Fold CV Recall: 0.72707182320442\n",
      "5-Fold CV F1 Score: 0.7811997062364262\n",
      "5-Fold CV Micro F1 Score: 0.8007017738975699\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7990983671260622\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa + distant on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVwXBK-03SbE"
   },
   "source": [
    "### ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7tbu6f3RqZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='electra', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1620818807674,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "TZLodIFy3o7l",
    "outputId": "a3d3f877-6160-4bb6-b6ae-d670072d0466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ELECTRA on SG1\n",
      "5-Fold CV Loss: 0.5440825581550598\n",
      "5-Fold CV Accuracy: 0.7448009918883706\n",
      "5-Fold CV Precision: 0.7614052309887166\n",
      "5-Fold CV Recall: 0.6966442953020134\n",
      "5-Fold CV F1 Score: 0.7211321040106528\n",
      "5-Fold CV Micro F1 Score: 0.7448009918883706\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7422210680339413\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for ELECTRA on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds_QU-K43jgD"
   },
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='electra', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1620819133471,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9CvLJFmM3rgB",
    "outputId": "bdb23da3-a285-4ea4-c144-dca0f17a59f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ELECTRA on SG2\n",
      "5-Fold CV Loss: 0.5140148580074311\n",
      "5-Fold CV Accuracy: 0.7625935605849968\n",
      "5-Fold CV Precision: 0.809470758694404\n",
      "5-Fold CV Recall: 0.6861878453038674\n",
      "5-Fold CV F1 Score: 0.7379172614803242\n",
      "5-Fold CV Micro F1 Score: 0.7625935605849969\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7597981280791523\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for ELECTRA on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhsBtQ_S3tcC"
   },
   "source": [
    "### XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49GtDW9A3u79"
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='xlnet', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1034722,
     "status": "ok",
     "timestamp": 1620820431129,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "L18ta1df3_8R",
    "outputId": "099993a2-69c6-42a0-9e40-4008d59f2d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XLNET on SG1\n",
      "5-Fold CV Loss: 0.5028677642345428\n",
      "5-Fold CV Accuracy: 0.7616525868953054\n",
      "5-Fold CV Precision: 0.7908365542157949\n",
      "5-Fold CV Recall: 0.6939597315436242\n",
      "5-Fold CV F1 Score: 0.7374808169992624\n",
      "5-Fold CV Micro F1 Score: 0.7616525868953054\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7600315195814671\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for XLNET on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1747441,
     "status": "ok",
     "timestamp": 1620822883385,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "OR8tCwlo37bb",
    "outputId": "0a85a6b1-c2ad-430b-a807-20bc9278042a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5651WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.5646 - val_loss: 0.4400\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.3625 - val_loss: 0.5188\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.4400\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5888WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 119s 1s/step - loss: 0.5882 - val_loss: 0.4410\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.3883 - val_loss: 0.4071\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.2283 - val_loss: 0.4403\n",
      "23/23 [==============================] - 7s 306ms/step - loss: 0.4071\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6144WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.6138 - val_loss: 0.4555\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.4001 - val_loss: 0.4433\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.2120 - val_loss: 0.4951\n",
      "23/23 [==============================] - 6s 283ms/step - loss: 0.4433\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5820WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 121s 1s/step - loss: 0.5813 - val_loss: 0.4738\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.3515 - val_loss: 0.5895\n",
      "23/23 [==============================] - 7s 324ms/step - loss: 0.4738\n",
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5740WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.5735 - val_loss: 0.4463\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 96s 1s/step - loss: 0.3819 - val_loss: 0.4720\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.4463\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='xlnet', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1620822884448,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "jgr6g6HG4FVX",
    "outputId": "07a0ed39-f26b-4c99-d32b-46a27679d9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XLNET on SG2\n",
      "5-Fold CV Loss: 0.4420862317085266\n",
      "5-Fold CV Accuracy: 0.7974357263341304\n",
      "5-Fold CV Precision: 0.8162492174406484\n",
      "5-Fold CV Recall: 0.76353591160221\n",
      "5-Fold CV F1 Score: 0.7870615420108473\n",
      "5-Fold CV Micro F1 Score: 0.7974357263341304\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7967053530729449\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for XLNET on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CycNYDUX--EY",
    "9xfkXD3PYX8R",
    "79o0mpSaYX8Z",
    "xwsmR_nqYX8d"
   ],
   "name": "classification_emnlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('cr4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "740471d2bc5e6e0b41d12bdc2e64373746aa6a34800f381ff958ff5f02fa0c53"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ab695abc740b0b23b80b6d47354e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "05de6e41179248a1abeaff4c3d248398": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1087a4b82b424e76a9869590d3944af4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ff2fa37c94e412c836224c447fe6bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9f8a2524f8a4c17a197a8078e31ce49",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d632b1a86e4e4492b99cf549e3f021ec",
      "value": 231508
     }
    },
    "22dde6c419744d6aa222309d784fd108": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26ae333f14b142868be336015e64abb2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae726ea844c7435c9c9db6ff31848be3",
      "value": 231508
     }
    },
    "23855aa0fb6244d98d5044da23814836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3245d896e7c4f158ab0b4da76ea93a4",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2f751936f5746ae939295cb88367292",
      "value": 28
     }
    },
    "2655bffd46c64f1f82b98d6bce0b1e73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26ae333f14b142868be336015e64abb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26c6e7e422e44eefa842bfaf9e33ad03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1087a4b82b424e76a9869590d3944af4",
      "placeholder": "​",
      "style": "IPY_MODEL_05de6e41179248a1abeaff4c3d248398",
      "value": " 363M/363M [00:06&lt;00:00, 56.0MB/s]"
     }
    },
    "29349e0af5804f088ee778f08d7b482a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "296a2491f36e44b0bfbda55362e69874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9478c98deb464cbf87aefa08ad3cf4ea",
       "IPY_MODEL_fe5bf9b7cbc84353bd8091c3f23acf18"
      ],
      "layout": "IPY_MODEL_a228898978784790a1f0f41a2da5881c"
     }
    },
    "2c58f409b9e64b3ba9a6bca68cd193c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38ce582a81e549f3bf356693dbe2d558",
      "placeholder": "​",
      "style": "IPY_MODEL_c850cf5b66ee45a698b5a32eddff5c30",
      "value": " 442/442 [00:00&lt;00:00, 2.36kB/s]"
     }
    },
    "311c872733504f0a804f73f6f49a9ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "333fd819aafa426892022abb6a72552d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3372ecb786754704b2321f47ad4263d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3395978288894e6cbcad914695ead617": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38ce582a81e549f3bf356693dbe2d558": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6867a6625c4f9890040cabfc57f3a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dbd5593c44f408d96fb8906984045d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22dde6c419744d6aa222309d784fd108",
       "IPY_MODEL_7260901878224b42aed032408c11be0c"
      ],
      "layout": "IPY_MODEL_3372ecb786754704b2321f47ad4263d3"
     }
    },
    "3dde9e7cce1d4c4ab58af138ce8015fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46ce1f04fe3140f5962fa05c7cc71f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cd630bd8b0c4cdeb8ca7cf567939c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b09076acca74b3e938312ad24850080",
       "IPY_MODEL_2c58f409b9e64b3ba9a6bca68cd193c4"
      ],
      "layout": "IPY_MODEL_2655bffd46c64f1f82b98d6bce0b1e73"
     }
    },
    "52c26cbdfa3a41b3979d37f8d504efd6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553ed5546d45464db8cfa1c67fee040a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_311c872733504f0a804f73f6f49a9ea4",
      "placeholder": "​",
      "style": "IPY_MODEL_d499b2c8dc88467ca3fb077c364163cf",
      "value": " 466k/466k [00:00&lt;00:00, 1.35MB/s]"
     }
    },
    "5c3ba5b9183d4fe697e84337907920b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62c8991c62e346dca0041cda351edb97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6b09076acca74b3e938312ad24850080": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bc7e65f21f54fb6acc90b64925365a3",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_333fd819aafa426892022abb6a72552d",
      "value": 442
     }
    },
    "6bc7e65f21f54fb6acc90b64925365a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c52cabb9ece48b58ceb073437fdc439": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23855aa0fb6244d98d5044da23814836",
       "IPY_MODEL_dbeee3b64dc94284a4775f2a0cb4dfa4"
      ],
      "layout": "IPY_MODEL_e46833e1a05e48ae8b1c6087bb00ee0f"
     }
    },
    "7260901878224b42aed032408c11be0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c22c14995e3747889c496c46429d8bbd",
      "placeholder": "​",
      "style": "IPY_MODEL_cac0198656f247899aca5086c2b408be",
      "value": " 232k/232k [00:00&lt;00:00, 938kB/s]"
     }
    },
    "79df1255843b48aabe25b5ff547b5783": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bafa4dd539714c5b8100494b9b5bf071",
       "IPY_MODEL_553ed5546d45464db8cfa1c67fee040a"
      ],
      "layout": "IPY_MODEL_d19186b71be744899b772642934539e1"
     }
    },
    "7fa44254f5b6467791a4b508504f1b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81dd8afd3da148c084f84b3d34329812": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ff2fa37c94e412c836224c447fe6bf7",
       "IPY_MODEL_bfaab7f593fb4bd088a64592a8b53663"
      ],
      "layout": "IPY_MODEL_fc5f1f66fc694d668251a47e1e379f8b"
     }
    },
    "81e01b1fc1824ae6a795c324f05d43f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b77d22d29d34e44994386d132db4613": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ef26ad478f040b1808e510e1dd5330d",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dde9e7cce1d4c4ab58af138ce8015fe",
      "value": 466062
     }
    },
    "8ef26ad478f040b1808e510e1dd5330d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9478c98deb464cbf87aefa08ad3cf4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29349e0af5804f088ee778f08d7b482a",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62c8991c62e346dca0041cda351edb97",
      "value": 28
     }
    },
    "a0cc5026b48c406ca66ea232842b4649": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a228898978784790a1f0f41a2da5881c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae726ea844c7435c9c9db6ff31848be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1f3438d4f8449d8b8c07a8e5197aed5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bafa4dd539714c5b8100494b9b5bf071": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81e01b1fc1824ae6a795c324f05d43f7",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca24677e1d2f4431a14c60ba268bf0fb",
      "value": 466062
     }
    },
    "bfaab7f593fb4bd088a64592a8b53663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c3ba5b9183d4fe697e84337907920b8",
      "placeholder": "​",
      "style": "IPY_MODEL_46ce1f04fe3140f5962fa05c7cc71f28",
      "value": " 232k/232k [00:01&lt;00:00, 121kB/s]"
     }
    },
    "c22c14995e3747889c496c46429d8bbd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f751936f5746ae939295cb88367292": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c4b80324c25c4449a716802a2e509d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa846344c2e04735aaae4542988becb0",
       "IPY_MODEL_26c6e7e422e44eefa842bfaf9e33ad03"
      ],
      "layout": "IPY_MODEL_3395978288894e6cbcad914695ead617"
     }
    },
    "c850cf5b66ee45a698b5a32eddff5c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f8a2524f8a4c17a197a8078e31ce49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca24677e1d2f4431a14c60ba268bf0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cac0198656f247899aca5086c2b408be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caceb8515d614c109d4f74848530aa51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d19186b71be744899b772642934539e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3245d896e7c4f158ab0b4da76ea93a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d366be34c995437d9d2eae8b5fb311c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d499b2c8dc88467ca3fb077c364163cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4bd173bc89b41ccaac8f8e2d2ee9a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d632b1a86e4e4492b99cf549e3f021ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dbeee3b64dc94284a4775f2a0cb4dfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caceb8515d614c109d4f74848530aa51",
      "placeholder": "​",
      "style": "IPY_MODEL_3b6867a6625c4f9890040cabfc57f3a7",
      "value": " 28.0/28.0 [00:00&lt;00:00, 57.4B/s]"
     }
    },
    "e46833e1a05e48ae8b1c6087bb00ee0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9216fe34bc8441ab10e8737a7fa8c70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0cc5026b48c406ca66ea232842b4649",
      "placeholder": "​",
      "style": "IPY_MODEL_d4bd173bc89b41ccaac8f8e2d2ee9a89",
      "value": " 466k/466k [00:00&lt;00:00, 3.20MB/s]"
     }
    },
    "fa846344c2e04735aaae4542988becb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52c26cbdfa3a41b3979d37f8d504efd6",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_041ab695abc740b0b23b80b6d47354e8",
      "value": 363423424
     }
    },
    "fc5f1f66fc694d668251a47e1e379f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc6e2911e71c44798ed76cdcec7ad099": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b77d22d29d34e44994386d132db4613",
       "IPY_MODEL_f9216fe34bc8441ab10e8737a7fa8c70"
      ],
      "layout": "IPY_MODEL_d366be34c995437d9d2eae8b5fb311c0"
     }
    },
    "fe5bf9b7cbc84353bd8091c3f23acf18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1f3438d4f8449d8b8c07a8e5197aed5",
      "placeholder": "​",
      "style": "IPY_MODEL_7fa44254f5b6467791a4b508504f1b40",
      "value": " 28.0/28.0 [00:16&lt;00:00, 1.69B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
